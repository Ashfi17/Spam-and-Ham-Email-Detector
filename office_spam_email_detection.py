# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D4lI-IKxK62DbSoKA23ObJ5PhsSw3cv4
"""

import numpy as np
import pandas as pd
import re
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
import nltk
nltk.download('stopwords')
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_extraction.text import TfidfVectorizer

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('drive/My Drive/Colab Notebooks/SMSSpamCollection.txt', delimiter = '\t', header = None)

df_spam = df.rename(columns = {0:'labels', 1:'emails'})

df_spam.head()

le = LabelEncoder()
df_spam['labels'] = le.fit_transform(df_spam['labels'])
df_spam.head()

def email_to_words(raw_email):
  corpus = []
  
  letters_only = re.sub("[^a-zA-Z]", " ",raw_email) # remove all punctuations and numbers and replace with a space
  #3. convert to lower case and split
  words = letters_only.lower().split()
  #4 In python searching a set is much faster than searching in list
  stops = set(stopwords.words('english'))
  #5. Remove stopwords
  meaningful_words = [w for w in words if not w in stops]
  #6
  return(' '.join(meaningful_words))

df_spam['emails'].size

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #Get number of reviews
# num_emails = df_spam['labels'].size
# # initialize an empty array 
# clean_train_emails = []
# # loop over each review 
# print("Cleaning and parsing.....\n")
# for i in range(0,num_emails):
#   if((i+1)%1000 == 0):
#     print("Email %d of %d \n"%(i+1,num_emails))
#   clean_train_emails.append(email_to_words(df_spam['emails'][i]))

cv = CountVectorizer(max_features = 1000)
X = cv.fit_transform(clean_train_emails)
y = df_spam['labels'].values

cv.vocabulary_

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2)

X_train

# Commented out IPython magic to ensure Python compatibility.
# %%time
# print("Training the model using count vectorization model...\n")
# classifier_cv = RandomForestClassifier(n_estimators = 60)
# classifier_cv.fit(X_train,y_train)
# y_pred = classifier_cv.predict(X_test)
# print("Accuracy score is: ",accuracy_score(y_pred,y_test))

sentence = ['Free free free you are credited 500 coins ']
sentence = cv.transform(sentence)

classifier_cv.predict(sentence)

